{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Measuring classes similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the machine learning experiments we ran, a new hypothesis emerged, which is that the different classes in our aggregate measure of vascular risk might be similar between them. Therefore, making the multi class classification problem very difficult to differentiate them. The most differentiated classes appeared to be patients with zero VRFs, the most healthy ones, and patients with five VRFs, the most at risk, because when comparing them we achieved the highest performance metrics. However, these hypothesis need to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 1427)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the data\n",
    "data = pd.read_csv('casuality_data_final_factor_analyzer.csv')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2065, 1384)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtering data groups and combining datasets\n",
    "heart_df = data.filter(regex='heart')\n",
    "cardio_cmr_df = data.filter(regex='cardio_cmr')\n",
    "brain_df = data.filter(regex='brain')\n",
    "agg_score = data['agg_score']\n",
    "data = pd.concat((heart_df, cardio_cmr_df, brain_df, agg_score), axis=1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523, 1384), (606, 1384), (555, 1384), (273, 1384), (91, 1384), (17, 1384))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting each class from our target variable\n",
    "S_0 = data.loc[data['agg_score'] == 0]\n",
    "S_1 = data.loc[data['agg_score'] == 1]\n",
    "S_2 = data.loc[data['agg_score'] == 2]\n",
    "S_3 = data.loc[data['agg_score'] == 3]\n",
    "S_4 = data.loc[data['agg_score'] == 4]\n",
    "S_5 = data.loc[data['agg_score'] == 5]\n",
    "S_0.shape, S_1.shape, S_2.shape, S_3.shape, S_4.shape, S_5.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracting factors from each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this reason we decided to extract five latent factors from each class with all the features included, the same number of factors we extracted for the ML experiments, and then run the k-means clustering algorithm from the Scikit-learn package in python to find the centroids for each factor in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y0 = S_0[\"agg_score\"]\n",
    "Y1 = S_1[\"agg_score\"]\n",
    "Y2 = S_2[\"agg_score\"]\n",
    "Y3 = S_3[\"agg_score\"]\n",
    "Y4 = S_4[\"agg_score\"]\n",
    "Y5 = S_5[\"agg_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((523, 5), (606, 5), (555, 5), (273, 5), (91, 5), (17, 5))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factor_S0 = FactorAnalysis(n_components=5).fit_transform(S_0, Y0)\n",
    "factor_S1 = FactorAnalysis(n_components=5).fit_transform(S_1, Y1)\n",
    "factor_S2 = FactorAnalysis(n_components=5).fit_transform(S_2, Y2)\n",
    "factor_S3 = FactorAnalysis(n_components=5).fit_transform(S_3, Y3)\n",
    "factor_S4 = FactorAnalysis(n_components=5).fit_transform(S_4, Y4)\n",
    "factor_S5 = FactorAnalysis(n_components=5).fit_transform(S_5, Y5)\n",
    "factor_S0.shape, factor_S1.shape, factor_S2.shape, factor_S3.shape, factor_S4.shape, factor_S5.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. K-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This algorithm clusters data by trying to separate samples in n groups of equal variance. For this task the k-means algorithm divides a set of samples into disjoint clusters , each described by the mean of the samples in the cluster. These means are known as the cluster “centroids” [1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO\n",
    "from sklearn.cluster import KMeans\n",
    "Kmean_S0 = KMeans(n_clusters=1)\n",
    "Kmean_S0.fit(factor_S0)\n",
    "centroid_SO = Kmean_S0.cluster_centers_.tolist()\n",
    "\n",
    "# S1\n",
    "Kmean_S1 = KMeans(n_clusters=1)\n",
    "Kmean_S1.fit(factor_S1)\n",
    "centroid_S1 = Kmean_S1.cluster_centers_.tolist()\n",
    "\n",
    "# S2\n",
    "Kmean_S2 = KMeans(n_clusters=1)\n",
    "Kmean_S2.fit(factor_S2)\n",
    "centroid_S2 = Kmean_S2.cluster_centers_.tolist()\n",
    "\n",
    "# S3\n",
    "Kmean_S3 = KMeans(n_clusters=1)\n",
    "Kmean_S3.fit(factor_S3)\n",
    "centroid_S3 = Kmean_S3.cluster_centers_.tolist()\n",
    "\n",
    "# S4\n",
    "Kmean_S4 = KMeans(n_clusters=1)\n",
    "Kmean_S4.fit(factor_S4)\n",
    "centroid_S4 = Kmean_S4.cluster_centers_.tolist()\n",
    "\n",
    "# S5\n",
    "Kmean_S5 = KMeans(n_clusters=1)\n",
    "Kmean_S5.fit(factor_S5)\n",
    "centroid_S5 = Kmean_S5.cluster_centers_.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plotting cluster centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be able to plot the results and visualize the distances between our classes, we will just select the first two centroids derived from the first two latent factors from each class to be able to plot them in a two dimensional graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.6281855829588817e-16, -7.518948285319894e-16]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_SO[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-3.0153272618068145e-16, -1.3703742944218102e-16]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_S1[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-2.9949766390648226e-16, -1.401281493243103e-16]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_S2[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-6.100126508929432e-17, 3.0093957444051864e-16]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_S3[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.342448579428902e-16, 2.5486328554307165e-15]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_S4[0][:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-5.1592717026698455e-16, 1.6718652606120006e-15]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroid_S5[0][:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Figures/kmeanscluster.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot we can see how S5, patients with an aggregate score of five, and S0, patients with an aggregate score of zero, are the most distant ones, reinforcing our hypothesis that these two classes differ the most. Also, the second largest distance is between S0 and S4, which shows why the comparison between these two aggregate measures achieved the second highest performance metrics after 0vs5. Lastly, S1, S2 and S3 are the closest aggregate measures to S0, showing why these comparisons obtained the lowest performance metrics and why they are the most similar classes from our target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] [Pedregosa, F. et al. (2011)](https://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf). Scikit-learn: Machine Learning in Python."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
